{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Takes results of one case-study-based evaluation through Evaluator.exe and Preciser.exe and computes precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'guardian' # 'webmd', 'walmart', 'guardian', 'cnn'\n",
    "participants = ['P1', 'P2', 'P3', 'P4']\n",
    "evaluation = 'gt-' + site\n",
    "dataset_evaluation_dir = 'C:/GazeMiningDataset/Dataset_evaluation/case-study'\n",
    "dataset_stimuli_dir = r'C:/GazeMiningDataset/Dataset_stimuli'\n",
    "\n",
    "# Build up pathes\n",
    "labels_screencasts_filepath = dataset_evaluation_dir + '/' + evaluation + '-screencasts.csv'\n",
    "labels_stimuli_filepath = dataset_evaluation_dir + '/' + evaluation + '-stimuli.csv'\n",
    "contrib_filepath = dataset_evaluation_dir + '/' + evaluation + '-contrib.csv'\n",
    "events_filepath = dataset_evaluation_dir + '/' + evaluation + '-events.csv'\n",
    "stimuli_dir = dataset_stimuli_dir + '/' + site + '/stimuli'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluator labels of stimuli\n",
    "stimuli_df = pd.read_csv(labels_stimuli_filepath)\n",
    "\n",
    "# Load evaluator labels of screencasts\n",
    "screencasts_df = pd.read_csv(labels_screencasts_filepath)\n",
    "\n",
    "# Load contribution (this tells one which frames as contained in the stimuli contributed to the element in the task)\n",
    "contrib_df = pd.read_csv(contrib_filepath)\n",
    "\n",
    "# Load events\n",
    "events_df = pd.read_csv(events_filepath, header=None, names=['timestamp', 'type', 'event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process events for general information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_changes_df = events_df[(events_df.type == 'mode_change')]\n",
    "\n",
    "# Get timestamps\n",
    "start_ts = int(mode_changes_df[(mode_changes_df.event == 'mode_start')].timestamp)\n",
    "videos_ts = int(mode_changes_df[(mode_changes_df.event == 'mode_videos')].timestamp)\n",
    "stimuli_ts = int(mode_changes_df[(mode_changes_df.event == 'mode_stimuli')].timestamp)\n",
    "end_ts = int(mode_changes_df[(mode_changes_df.event == 'mode_end')].timestamp)\n",
    "\n",
    "# Compute durations of modes\n",
    "video_duration = 0\n",
    "stimuli_duration = 0\n",
    "if videos_ts > stimuli_ts:\n",
    "    video_duration = end_ts - videos_ts\n",
    "    stimuli_duration = videos_ts - stimuli_ts\n",
    "else:\n",
    "    video_duration = stimuli_ts - videos_ts\n",
    "    stimuli_duration = end_ts - stimuli_ts\n",
    "    \n",
    "# Print results\n",
    "print('Video Mode [s]: ' + str(video_duration/1000) + ', Stimuli Mode [s]: ' + str(stimuli_duration/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get infos about visual stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_without_AOI = len(stimuli_df.index[stimuli_df.label == 0])\n",
    "stimuli_with_AOI = len(stimuli_df.index[stimuli_df.label == 1])\n",
    "\n",
    "print(\"Stimuli count: \" + str(stimuli_without_AOI + stimuli_with_AOI))\n",
    "print(\"Stimuli count display AOI: \" + str(stimuli_with_AOI))\n",
    "print(\"Stimuli count do not display AOI: \" + str(stimuli_without_AOI))                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect frames represented by marked stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make groups by layer id from labeled stimuli\n",
    "layers = stimuli_df.groupby(['layer_id'])\n",
    "\n",
    "# Set of frames that are represented by the stimuli\n",
    "marked_stimuli_frames = defaultdict(set) # participant_id -> set of frames\n",
    "\n",
    "# Go over layer groups\n",
    "for layer_id, data in layers:\n",
    "    \n",
    "    # Get ids of stimuli that are marked\n",
    "    marked_stimuli_ids = data[data.label == 1]['stimulus_id']\n",
    "    \n",
    "    # Go over marked stimuli and collect all represented frames across shots per screencast\n",
    "    for stimulus_id in marked_stimuli_ids:\n",
    "        df = pd.read_csv(stimuli_dir + '/' + layer_id + '/' + str(stimulus_id) +'-shots.csv') # read in information about stimulus (which frames are contained...)\n",
    "        for index, row in df.iterrows(): # go over contained shots and collect the frames\n",
    "            frames = list(range(row['frame_idx_start'], row['frame_idx_end']+1, 1))\n",
    "            participant_id = row['session_id'][:2].upper()\n",
    "            marked_stimuli_frames[participant_id].update(frames) # put frames into the set, one set per screencast\n",
    "            \n",
    "# print(marked_stimuli_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some duplicated frames in the contrib files, fix that\n",
    "# Note: This happens, when one frame is separated for stimuli discovery\n",
    "# into more than one layer and the element is found on both layers in the evaluation\n",
    "groups = contrib_df.groupby(['session'])\n",
    "new_df = pd.DataFrame()\n",
    "for key in groups.groups.keys():\n",
    "    df = groups.get_group(key)\n",
    "    df = df.drop_duplicates(subset='frame_idx')\n",
    "    new_df = new_df.append(df, ignore_index=True)\n",
    "contrib_df = new_df\n",
    "\n",
    "print('Contrib Frame Count: ' + str(contrib_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_contrib_count = contrib_df[contrib_df.label == 'POS_CONTRIB'].shape[0]\n",
    "neg_contrib_count = contrib_df[contrib_df.label == 'NEG_CONTRIB'].shape[0]\n",
    "neutral_count = contrib_df[contrib_df.label == 'NEUTRAL'].shape[0]\n",
    "\n",
    "print('POS_CONTRIB: ' + str(pos_contrib_count))\n",
    "print('NEG_CONTRIB: ' + str(neg_contrib_count))\n",
    "print('NEUTRAL: ' + str(neutral_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect frames marked in screencasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marked frames of screencasts\n",
    "marked_screencast_frames = {}\n",
    "marked_screencast_frames['P1'] = screencasts_df.index[screencasts_df.P1 == 1]\n",
    "marked_screencast_frames['P2'] = screencasts_df.index[screencasts_df.P2 == 1]\n",
    "marked_screencast_frames['P3'] = screencasts_df.index[screencasts_df.P3 == 1]\n",
    "marked_screencast_frames['P4'] = screencasts_df.index[screencasts_df.P4 == 1]\n",
    "\n",
    "print(marked_screencast_frames)\n",
    "\n",
    "# Count frames\n",
    "p1_no = len(screencasts_df.index[screencasts_df.P1 == 0])\n",
    "p1_yes = len(screencasts_df.index[screencasts_df.P1 == 1])\n",
    "p2_no = len(screencasts_df.index[screencasts_df.P2 == 0])\n",
    "p2_yes = len(screencasts_df.index[screencasts_df.P2 == 1])\n",
    "p3_no = len(screencasts_df.index[screencasts_df.P3 == 0])\n",
    "p3_yes = len(screencasts_df.index[screencasts_df.P3 == 1])\n",
    "p4_no = len(screencasts_df.index[screencasts_df.P4 == 0])\n",
    "p4_yes = len(screencasts_df.index[screencasts_df.P4 == 1])\n",
    "\n",
    "print('Annotated Frames: ' + str(p1_no + p1_yes + p2_no + p2_yes + p3_no + p3_yes + p4_no + p4_yes))\n",
    "print('Display AOI: ' + str(p1_yes + p2_yes + p3_yes + p4_yes))\n",
    "print('Do not display AOI: ' + str(p1_no + p2_no + p3_no + p4_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both dictionaries\n",
    "stimuli_frames_count = 0;\n",
    "recall_count = 0\n",
    "screencast_frames_count = 0\n",
    "for participant in participants:\n",
    "    \n",
    "    # Get frames marked (indirectly) in stimuli and screencasts\n",
    "    stimuli_frames = set(marked_stimuli_frames[participant])\n",
    "    screencast_frames = set(marked_screencast_frames[participant])\n",
    "    stimuli_frames_count += len(stimuli_frames)\n",
    "    screencast_frames_count += len(screencast_frames)\n",
    "    \n",
    "    # Compute recall\n",
    "    recall_count += len(screencast_frames.intersection(stimuli_frames)) # frames that are contained in both sets\n",
    "\n",
    "print('Stimuli Frames Count: ' + str(stimuli_frames_count))\n",
    "print('Screencast Frames Count: ' + str(screencast_frames_count))\n",
    "print('Precision: ' + str(pos_contrib_count / (pos_contrib_count + neg_contrib_count)))\n",
    "print('Recall: ' + str(recall_count / screencast_frames_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
